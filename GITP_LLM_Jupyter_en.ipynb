{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60eab687-cdcc-4ffe-aa61-b0c1cda045a1",
   "metadata": {},
   "source": [
    "# This script annotates transcripts of video simulation role-playing exercises from job candidates using large language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3544d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries that might not be installed as necessary (adjust manually)\n",
    "# !pip install openai\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7acacb89-5316-4382-b343-44a95c60641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import openai          # OpenAI API for AI model access\n",
    "from openai import OpenAI  # The main client class for interacting with OpenAI's API\n",
    "import requests        # HTTP library for making web requests (API calls, downloading data, etc.)\n",
    "import re              # Regular expressions\n",
    "import os              # Operating system interface\n",
    "import pandas as pd    # DataFrames for tabular data manipulation and analysis\n",
    "import numpy as np     # Numerical computing\n",
    "import time            # Time-related functions\n",
    "import random          # Random number generation\n",
    "\n",
    "# set seed for reproducibility\n",
    "random.seed(1337)  # Sets seed for Python's random module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c1b20-7c04-4ff2-960f-a297a62ae85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Advisement 2\n",
    "advise = pd.read_csv(\"data_advise_text.csv\")\n",
    "# advise = advise.iloc[:2] # keep only first two rows for pilot data analysis purposes\n",
    "# advise.head()\n",
    "\n",
    "# # Change management 2\n",
    "# change_manage = pd.read_csv(\"data_change_manage_text.csv\")\n",
    "# # Team management 2\n",
    "# team_manage = pd.read_csv(\"data_team_manage_text.csv\")\n",
    "# # Team work 2\n",
    "# team_work = pd.read_csv(\"data_team_work_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738e43e-0ef8-455a-a787-ee8849a94b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenAI API key\n",
    "client = OpenAI(api_key=\"enter_key_here\") # key hidden for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72284956-a623-4510-8817-351cce03150c",
   "metadata": {},
   "source": [
    "## Function to get ratings from openai API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fa709a4-ca13-48fd-b447-15a36afb855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually change `model` to another openai model (as desired)\n",
    "def get_rating(client, text, prompt_template, model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Query the OpenAI model for a 1–5 rating based on a formatted prompt with transcript text.\n",
    "    \n",
    "    Parameters:\n",
    "    - client: OpenAI client instance\n",
    "    - text (str): The transcript to evaluate\n",
    "    - prompt_template (str): A prompt string with {text} placeholder for transcript\n",
    "    - model (str): Model name (default: gpt-4o)\n",
    "\n",
    "    Returns:\n",
    "    - int or None: Extracted rating or None if parsing fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        full_prompt = prompt_template.format(text=text.strip())\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": full_prompt},\n",
    "                {\"role\": \"user\", \"content\": \"\"}  # no additional input\n",
    "            ],\n",
    "            temperature=0.7, # lower values reduce randomness (0.7 matches the ChatGPT behavior)\n",
    "            max_tokens=5  # we expect only a single digit\n",
    "        )\n",
    "\n",
    "        rating_text = response.choices[0].message.content.strip()\n",
    "        match = re.search(r'\\b([1-5](?:\\.\\d)?)\\b', rating_text)\n",
    "        if match:\n",
    "            return int(match.group(0))\n",
    "        else:\n",
    "            print(f\"Warning: Non-numeric or out-of-range response: '{rating_text}'\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ebea53-a986-48ac-9030-d354784a5ed5",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7726e209-9188-49b9-b27d-87d6b62a86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define general instructions for competence annotation\n",
    "context = \"\"\"\n",
    "**Context of the role-playing exercise:**\n",
    "You are a professional recruiter. Your task is to evaluate a job candidate based on their responses \n",
    "in a role-playing exercise. In this exercise, the candidate responds verbally to a fictional colleague named Lara, across four scenes. \n",
    "Lara shares professional frustrations, mistakes with client projects, emotional exhaustion, \n",
    "and personal financial concerns, and she asks the candidate for support and advice. In summary:\n",
    "\n",
    "- **Scene 1**: Lara expresses frustration about being overlooked at work, doing repetitive tasks, \n",
    "and lacking opportunities to grow. She asks for advice.\n",
    "- **Scene 2**: Lara confesses she mishandled two client projects, causing cost issues and customer dissatisfaction. \n",
    "She is afraid to tell the team leader and asks if the candidate can speak on her behalf.\n",
    "- **Scene 3**: Lara reveals emotional exhaustion and financial stress due to her daughter’s chronic illness. \n",
    "She wonders if she can get extra leave or if the candidate can take over some tasks.\n",
    "- **Scene 4**: Lara feels slightly better but still overwhelmed. She asks the candidate for concrete advice on what to do next.\n",
    "\"\"\"\n",
    "\n",
    "instructions = \"\"\"\n",
    "**Candidate Response:**\n",
    "You are given the transcript of the candidate’s full response across all four scenes below.\n",
    "\n",
    "**Evaluation Instructions:**\n",
    "1. Read the transcript of the job candidate's reponse (delimeated between the triple backticks).\n",
    "2. Focus on **verbal behaviors, values, or attitudes** that reflect this competency.\n",
    "3. Rate the candidate on a **1 to 5 scale**, using the following rubric:\n",
    "\n",
    "- **1** = Poor  \n",
    "- **2** = Fair  \n",
    "- **3** = Satisfactory  \n",
    "- **4** = Good  \n",
    "- **5** = Excellent\n",
    "\n",
    "**Output only a single number from 1 to 5. Do not provide any explanation.**\n",
    "\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Prompts for rating job competencies\n",
    "promptAD_PROBL_I1 = f\"\"\"\n",
    "{context}\n",
    "**Competency to evaluate:**  \n",
    "Evaluate **to what extent the candidate distinguishes between main and side issues** in Lara’s story.\n",
    "{instructions}\n",
    "\"\"\"\n",
    "\n",
    "promptAD_PROBL_I2 = f\"\"\"\n",
    "{context}\n",
    "**Competency to evaluate:**  \n",
    "Evaluate **to what extent the candidate makes connections between different aspects of the issue** in Lara’s story.\n",
    "{instructions}\n",
    "\"\"\"\n",
    "\n",
    "promptAD_PROBL_I3 = f\"\"\"\n",
    "{context}\n",
    "**Competency to evaluate:**  \n",
    "Evaluate **to what extent the candidate identifies the core of the information** in Lara’s story.\n",
    "{instructions}\n",
    "\"\"\"\n",
    "\n",
    "promptAD_CREAT_I1 = f\"\"\"\n",
    "{context}\n",
    "**Competency to evaluate:**  \n",
    "Evaluate **to what extent the candidate comes up with original ideas** as a response to Lara's story.\n",
    "{instructions}\n",
    "\"\"\"\n",
    "\n",
    "promptAD_CREAT_I2 = f\"\"\"\n",
    "{context}\n",
    "**Competency to evaluate:**  \n",
    "Evaluate **to what extent the candidate approaches matters from multiple perspectives when generating solutions/ideas** as a response to Lara's story.\n",
    "{instructions}\n",
    "\"\"\"\n",
    "\n",
    "promptAD_CREAT_I3 = f\"\"\"\n",
    "{context}\n",
    "**Competency to evaluate:**  \n",
    "Evaluate **to what extent the candidate combines existing elements into something new** in their response to Lara's story.\n",
    "{instructions}\n",
    "\"\"\"\n",
    "\n",
    "promptAD_OORDE_I1 = f\"\"\"\n",
    "{context}\n",
    "**Competency to evaluate:**  \n",
    "Evaluate **to what extent the candidate distinguishes between relevant and irrelevant aspects** in their response to Lara's story.\n",
    "{instructions}\n",
    "\"\"\"\n",
    "\n",
    "promptAD_OORDE_I2 = f\"\"\"\n",
    "{context}\n",
    "**Competency to evaluate:**  \n",
    "Evaluate **to what extent the candidate supports their reasoning with facts** in their response to Lara's story.\n",
    "{instructions}\n",
    "\"\"\"\n",
    "\n",
    "promptAD_OORDE_I3 = f\"\"\"\n",
    "{context}\n",
    "**Competency to evaluate:**  \n",
    "Evaluate **to what extent the candidate states both pros and cons of their own standpoint** in their response to Lara's story.\n",
    "{instructions}\n",
    "\"\"\"\n",
    "\n",
    "promptAD_ORGANS_I1 = f\"\"\"\n",
    "{context}\n",
    "**Competency to evaluate:**  \n",
    "Evaluate **to what extent the candidate takes into account the sensitivities of others in the organization during the conversation** in their response to Lara's story.\n",
    "{instructions}\n",
    "\"\"\"\n",
    "\n",
    "promptAD_ORGANS_I2 = f\"\"\"\n",
    "{context}\n",
    "**Competency to evaluate:**  \n",
    "Evaluate **to what extent the candidate checks in advance how actions/decisions will be received within the organization** in their response to Lara's story.\n",
    "{instructions}\n",
    "\"\"\"\n",
    "\n",
    "promptAD_ORGANS_I3 = f\"\"\"\n",
    "{context}\n",
    "**Competency to evaluate:**  \n",
    "Evaluate **to what extent the candidate investigates the consequences for other people/organizational units before making a decision** in their response to Lara's story.\n",
    "{instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd10eb3a-0e4e-4724-b5a5-957862e4c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new columns to store the annotations\n",
    "\n",
    "# Specify which LLM model is being used for annotations\n",
    "# This will be prefixed to all generated column names (e.g., \"4o_rating607A\")\n",
    "MODEL_USED = \"4o\"  # Options: \"4o\", \"R1\", \"gpt4\", etc.\n",
    "\n",
    "# Dictionary mapping source columns to their respective rating columns and prompts\n",
    "annotation_config = {\n",
    "    \"Beoordeling.all\": [\n",
    "        (f\"{MODEL_USED}_AD_PROBL_I1\", promptAD_PROBL_I1),\n",
    "        (f\"{MODEL_USED}_AD_PROBL_I2\", promptAD_PROBL_I2),\n",
    "        (f\"{MODEL_USED}_AD_PROBL_I3\", promptAD_PROBL_I3),\n",
    "        (f\"{MODEL_USED}_AD_CREAT_I1\", promptAD_CREAT_I1),\n",
    "        (f\"{MODEL_USED}_AD_CREAT_I2\", promptAD_CREAT_I2),\n",
    "        (f\"{MODEL_USED}_AD_CREAT_I3\", promptAD_CREAT_I3),\n",
    "        (f\"{MODEL_USED}_AD_OORDE_I1\", promptAD_OORDE_I1),\n",
    "        (f\"{MODEL_USED}_AD_OORDE_I2\", promptAD_OORDE_I2),\n",
    "        (f\"{MODEL_USED}_AD_OORDE_I3\", promptAD_OORDE_I3),\n",
    "        (f\"{MODEL_USED}_AD_ORGANS_I1\", promptAD_ORGANS_I1),\n",
    "        (f\"{MODEL_USED}_AD_ORGANS_I2\", promptAD_ORGANS_I2),\n",
    "        (f\"{MODEL_USED}_AD_ORGANS_I3\", promptAD_ORGANS_I3)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Initialize all rating columns with NaN values\n",
    "# Creates columns in format: \"{MODEL_USED}_ratingXXX\"\n",
    "for ratings in annotation_config.values():\n",
    "    for rating_col, _ in ratings:\n",
    "        advise[rating_col] = np.nan\n",
    "\n",
    "# Verify new columns were created successfully\n",
    "# display(advise.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4dbcb6-97c0-44d0-8a99-f449b7ae29d0",
   "metadata": {},
   "source": [
    "# Text annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "516b2437-6d76-4452-9796-60531a0f5c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each row in the advise DataFrame\n",
    "for idx, row in advise.iterrows():\n",
    "    try:\n",
    "        # Loop through each Beoordeling column and its associated ratings/prompts\n",
    "        for beoordeling_col, ratings in annotation_config.items():\n",
    "            \n",
    "            # Extract the transcript\n",
    "            text = row.get(beoordeling_col, \"\")\n",
    "            \n",
    "            if pd.notna(text) and text.strip() != \"\":\n",
    "                for rating_col, prompt_template in ratings:\n",
    "                    \n",
    "                    # Query the model with formatted prompt\n",
    "                    rating = get_rating(client, text, prompt_template)\n",
    "                    \n",
    "                    # Save the rating\n",
    "                    advise.loc[idx, rating_col] = rating\n",
    "                    \n",
    "                    # Add small delay to respect rate limits\n",
    "                    time.sleep(0.5)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Progress logging\n",
    "    if (idx + 1) % 5 == 0:\n",
    "        print(f\"Processed {idx + 1}/{len(advise)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average for each of the four sub-competencies and store in new columns\n",
    "advise[\"4o_AD_PROBL\"] = advise[[\"4o_AD_PROBL_I1\", \"4o_AD_PROBL_I2\", \"4o_AD_PROBL_I3\"]].mean(axis=1)\n",
    "advise[\"4o_AD_CREAT\"] = advise[[\"4o_AD_CREAT_I1\", \"4o_AD_CREAT_I2\", \"4o_AD_CREAT_I3\"]].mean(axis=1)\n",
    "advise[\"4o_AD_OORDE\"] = advise[[\"4o_AD_OORDE_I1\", \"4o_AD_OORDE_I2\", \"4o_AD_OORDE_I3\"]].mean(axis=1)\n",
    "advise[\"4o_AD_ORGANS\"] = advise[[\"4o_AD_ORGANS_I1\", \"4o_AD_ORGANS_I2\", \"4o_AD_ORGANS_I3\"]].mean(axis=1)\n",
    "\n",
    "# Calculate the average of the 4 new columns\n",
    "advise[\"4o_AD\"] = advise[[\"4o_AD_PROBL\", \"4o_AD_CREAT\", \"4o_AD_OORDE\", \"4o_AD_ORGANS\"]].mean(axis=1)\n",
    "\n",
    "# advise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bace650-ea24-4360-9078-63755436aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save results\n",
    "# advise.to_csv('annotated_advise.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53639959-00c1-4f0f-93a1-38ccbe4ae466",
   "metadata": {},
   "source": [
    "## Codebook\n",
    "\n",
    "The codebook below explains the column names of the datasets.  \n",
    "The original column names (e.g., `Score.566`) have been re-named such that the new names indicate:  \n",
    "\n",
    "**(a)** the job competency being evaluated (i.e., `AD` = Advisement, `CM` = Change management, `TM` = Team management, `TW` = Team work),  \n",
    "\n",
    "**(b)** the sub-dimension being evaluated (e.g., `PROBM` = Problem analysis),  \n",
    "\n",
    "**(c)** the number of the item of the subdimension (e.g., `I1` = item 1).  \n",
    "\n",
    "For instance, in the column name `AD_PROBL_I1`, `AD` refers to the competency of `Advisement`, `PROBL` refers to the sub-competence of `Problem analyse`, and `I1` refers to the first item (item 1) of that sub-compentence.\n",
    "\n",
    "\n",
    "**Advisement Codebook**:\n",
    "| Code_name | Original_column_name | Label |\n",
    "| -------- |-------------|-------|\n",
    "|Beoordeling.607 |Beoordeling.607 | Transcript scene2 |\n",
    "|Beoordeling.608 |Beoordeling.608 | Transcript scene3 |\n",
    "|Beoordeling.609 |Beoordeling.609 | Transcript scene4 |\n",
    "|Beoordeling.610 |Beoordeling.610 | Transcript scene5 |\n",
    "|Beoordeling.all |Beoordeling.all | Transcripts scene2 to scene5 |\n",
    "| AD_PROBL_I1 | Score.566   | Advisor's assessment: PROBL-I1_Maakt onderscheid tussen hoofd- en bijzaken in de situatie |\n",
    "| AD_PROBL_I2 | Score.567   | Advisor's assessment: PROBL-I2_Legt verbanden tussen verschillende aspecten van de vraagstelling |\n",
    "| AD_PROBL_I3 | Score.568   | Advisor's assessment: PROBL-I3_Benoemt de kern van de informatie |\n",
    "| AD_CREAT_I1 | Score.569   | Advisor's assessment: CREAT-I1_Komt met originele ideeën |\n",
    "| AD_CREAT_I2 | Score.570   | Advisor's assessment: CREAT-I2_Benadert zaken vanuit meerdere invalshoeken bij het bedenken van oplossingen/ideeën |\n",
    "| AD_CREAT_I3 | Score.571   | Advisor's assessment: CREAT-I3_Combineert bestaande zaken tot iets nieuws |\n",
    "| AD_OORDE_I1 | Score.1544 | Advisor's assessment: OORDE-I1_Maakt in zijn/haar/hen beeldvorming een onderscheid tussen relevante en niet relevante aspecten van een kwestie |\n",
    "| AD_OORDE_I2 | Score.1545 | Advisor's assessment: OORDE-I2_Onderbouwt zijn/haar/hen redenering met feiten |\n",
    "| AD_OORDE_I3 | Score.1546 | Advisor's assessment: OORDE-I3_Benoemt van eigen standpunt zowel voor- als nadelen |\n",
    "| AD_ORGANS_I1 | Score.1547 | Advisor's assessment: ORGANS-I1_Houdt in het gesprek rekening met gevoeligheden van anderen in de organisatie |\n",
    "| AD_ORGANS_I2 | Score.1548 | Advisor's assessment: ORGANS-I2_Toetst vooraf hoe acties/besluiten binnen de organisatie ontvangen zullen worden |\n",
    "| AD_ORGANS_I3 | Score.1549 | Advisor's assessment: ORGANS-I3_Onderzoekt de gevolgen voor andere personen/organisatie-onderdelen alvorens te besluiten |\n",
    "\n",
    "\n",
    "**Change management Codebook**:\n",
    "| Code_name | Original_column_name | Label |\n",
    "| -------- |-------------|-------|\n",
    "| CM_LEIDIN_I2 | Score.615  | Oordeel adviseur: LEIDIN-I2_Geeft aandacht aan goede prestaties van de medewerker, uit waardering |\n",
    "| CM_LEIDIN_I1 | Score.616  | Oordeel adviseur: LEIDIN-I1_Schept helderheid over de van de medewerker verwachte prestaties |\n",
    "| CM_LEIDIN_I3 | Score.617  | Oordeel adviseur: LEIDIN-I3_Past stijl van leidinggeven aan de situatie en persoon aan |\n",
    "| CM_COACH_I1 | Score.618  | Oordeel adviseur: COACH-I1_Helpt de ander inzicht te krijgen in diens sterke en zwakke punten |\n",
    "| CM_COACH_I2 | Score.619  | Oordeel adviseur: COACH-I2_Stimuleert de ander om zich te ontwikkelen en nieuwe uitdagingen aan te gaan |\n",
    "| CM_COACH_I3 | Score.620  | Oordeel adviseur: COACH-I3_Geeft ruimte om op een eigen manier te werken aan ontwikkeling |\n",
    "| CM_VISIEU_I1 | Score.627  | Oordeel adviseur: VISIEU-I1_Benoemt de (lange termijn) doelen voor de organisatie |\n",
    "| CM_VISIEU_I2 | Score.628  | Oordeel adviseur: VISIEU-I2_Geeft inzicht heeft in wat het beleid betekent voor de werkzaamheden |\n",
    "| CM_VISIEU_I3 | Score.629  | Oordeel adviseur: VISIEU-I3_Legt meer de nadruk op mogelijkheden in de toekomst dan op beperkingen \n",
    "| CM_RESUL_I1 | Score.621  | Oordeel adviseur: RESUL-I1_Komt met voorstellen over hoe doelen sneller of beter kunnen worden bereikt |\n",
    "| CM_RESUL_I2 | Score.622  | Oordeel adviseur: RESUL-I2_Maakt duidelijke afspraken met de medewerker over de te bereiken resultaten |\n",
    "| CM_RESUL_I3 | Score.623  | Oordeel adviseur: RESUL-I3_Grijpt tijdig in wanneer resultaten niet bereikt dreigen te worden; stuurt bij |\n",
    "\n",
    "**Team management Codebook**:\n",
    "| Code_name | Original_column_name | Label |\n",
    "| -------- |-------------|-------|\n",
    "| TM_LEIDIN_I2 | Score.615  | Oordeel adviseur: LEIDIN-I2_Geeft aandacht aan goede prestaties van de medewerker, uit waardering |\n",
    "| TM_LEIDIN_I1 | Score.616  | Oordeel adviseur: LEIDIN-I1_Schept helderheid over de van de medewerker verwachte prestaties |\n",
    "| TM_LEIDIN_I3 | Score.617  | Oordeel adviseur: LEIDIN-I3_Past stijl van leidinggeven aan de situatie en persoon aan |\n",
    "| TM_COACH_I1 | Score.618  | Oordeel adviseur: COACH-I1_Helpt de ander inzicht te krijgen in diens sterke en zwakke punten |\n",
    "| TM_COACH_I2 | Score.619  | Oordeel adviseur: COACH-I2_Stimuleert de ander om zich te ontwikkelen en nieuwe uitdagingen aan te gaan |\n",
    "| TM_COACH_I3 | Score.620  | Oordeel adviseur: COACH-I3_Geeft ruimte om op een eigen manier te werken aan ontwikkeling |\n",
    "| TM_OVERT_I1 | Score.552  | Oordeel adviseur: OVERT-I1_Gebruikt argumenten die aansluiten bij de belangen of voorkeuren van de medewerker |\n",
    "| TM_OVERT_I2 | Score.553  | Oordeel adviseur: OVERT-I2_Maakt duidelijk wat de voordelen van zijn/haar/diens voorstel zijn voor de medewerker |\n",
    "| TM_OVERT_I3 | Score.554  | Oordeel adviseur: OVERT-I3_Maakt weerstand van de medewerker bespreekbaar |\n",
    "| TM_RESUL_I1 | Score.621  | Oordeel adviseur: RESUL-I1_Komt met voorstellen over hoe doelen sneller of beter kunnen worden bereikt |\n",
    "| TM_RESUL_I2 | Score.622  | Oordeel adviseur: RESUL-I2_Maakt duidelijke afspraken met de medewerker over de te bereiken resultaten |\n",
    "| TM_RESUL_I3 | Score.623  | Oordeel adviseur: RESUL-I3_Grijpt tijdig in wanneer resultaten niet bereikt dreigen te worden; stuurt bij |\n",
    "\n",
    "\n",
    "**Team work Codebook**:\n",
    "| Code_name | Original_column_name | Label |\n",
    "| -------- |-------------|-------|\n",
    "| TW_SAMEN_I1 | Score.549  | Oordeel adviseur: SAMEN-I1_Biedt de collega hulp aan |\n",
    "| TW_SAMEN_I2 | Score.550  | Oordeel adviseur: SAMEN-I2_Stelt gezamenlijk belang boven het eigen belang |\n",
    "| TW_SAMEN_I3 | Score.551  | Oordeel adviseur: SAMEN-I3_Onderneemt acties die de samenwerking bevorderen |\n",
    "| TW_OVERT_I1 | Score.552  | Oordeel adviseur: OVERT-I1_Maakt duidelijk wat de voordelen zijn van zijn/haar/diens voorstel |\n",
    "| TW_OVERT_I2 | Score.553  | Oordeel adviseur: OVERT-I2_Gebruikt argumenten die aansluiten bij de belangen van de ander |\n",
    "| TW_OVERT_I3 | Score.554  | Oordeel adviseur: OVERT-I3_Maakt weerstand van de ander op gepaste manier bespreekbaar |\n",
    "| TW_MONDEC_I1 | Score.555  | Oordeel adviseur: MONDEC-I1_Brengt de boodschap op een voor de ander begrijpelijke manier over |\n",
    "| TW_MONDEC_I2 | Score.556  | Oordeel adviseur: MONDEC-I2_Verduidelijkt de boodschap met concrete voorbeelden |\n",
    "| TW_MONDEC_I3 | Score.557  | Oordeel adviseur: MONDEC-I3_Onderscheidt in zijn/haar/diens boodschap hoofd- en bijzaken op logische manier |\n",
    "| TW_ORGANE_I1 | Score.558  | Oordeel adviseur: ORGANE-I1_Stelt prioriteiten voor het eigen werk; belangrijke zaken eerst |\n",
    "| TW_ORGANE_I2 | Score.559  | Oordeel adviseur: ORGANE-I2_Houdt zich in het eigen werk aan met anderen gemaakte afspraken |\n",
    "| TW_ORGANE_I3 | Score.560  | Oordeel adviseur: ORGANE-I3_Laat tijdig aan de collega weten wanneer het eigen werk geen nieuwe bezigheden toelaat |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
